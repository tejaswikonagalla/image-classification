#below is the code for image classification
import tensorflow as tf
tf.__version__
RANDOM_SEED = 42
!pip install split-folders[full]
import splitfolders
splitfolders.ratio("/kaggle/input/wonders-of-the-world-image-classification/Wonders of World/Wonders of World", output="dataset_splitted",
    seed=RANDOM_SEED, ratio=(.8, .2,), group_prefix=None, move=False)
!rm -rf "/kaggle/working/dataset_splitted/val/Wonders of World"
!rm -rf "/kaggle/working/dataset_splitted/train/Wonders of World"
import os
def walk_through_dir(dir_path):
    for dirpath, dirnames, filenames in os.walk(dir_path):
        print(
            f"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.")
walk_through_dir("/kaggle/working/dataset_splitted")
import os
def walk_through_dir(dir_path):
    for dirpath, dirnames, filenames in os.walk(dir_path):
        print(
            f"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.")
walk_through_dir("/kaggle/working/dataset_splitted")
BATCH_SIZE = 32
EPOCHS = 5
IMAGE_SIZE= (400, 400)
LABEL_MODE = "categorical"
AUGMENTATION_FACTOR= 0.2
TRAIN_DIR = "dataset_splitted/train"
TEST_DIR = "dataset_splitted/val"
import random
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
def show_random_image_from_dataset(target_dir, class_names):
    if not target_dir:
        print("Please path a directory!")
        return
    if not os.path.isdir(target_dir):
        print("This directory path does not exist!")
        return
    target_class = random.choice(class_names)
    target_folder: str = target_dir + target_class
    random_image = random.sample(os.listdir(target_folder), 1)
    img = mpimg.imread(target_folder + "/" + random_image[0])
    plt.imshow(img)
    plt.title(target_class)
    print(f"Image shape: {img.shape}") # show the shape of the image
show_random_image_from_dataset(target_dir=f"{TRAIN_DIR}/", class_names=class_names)
print("training data ðŸ§ :")
train_data = tf.keras.preprocessing.image_dataset_from_directory(
    directory=TRAIN_DIR,
    batch_size=BATCH_SIZE,
    label_mode=LABEL_MODE,
    image_size=IMAGE_SIZE,
    seed=RANDOM_SEED,
    shuffle=True
)

print("test data ðŸ§ª:")
test_data = tf.keras.preprocessing.image_dataset_from_directory(
    directory=TEST_DIR,
    batch_size=BATCH_SIZE,
    label_mode=LABEL_MODE,
    image_size=IMAGE_SIZE,
    seed=RANDOM_SEED,
    shuffle=False
)
class_names = train_data.class_names
class_names, len(class_names), len(test_data.class_names)
from tensorflow.keras.layers import Dense, RandomFlip, RandomRotation, RandomZoom, RandomHeight, RandomWidth, Rescaling
from tensorflow.keras import Sequential
from tensorflow.keras.activations import softmax
augmentaion_layer = Sequential([
    RandomFlip("horizontal", seed=RANDOM_SEED),
    RandomRotation(AUGMENTATION_FACTOR, seed=RANDOM_SEED),
    RandomZoom(AUGMENTATION_FACTOR, seed=RANDOM_SEED),
    RandomHeight(AUGMENTATION_FACTOR, seed=RANDOM_SEED),
    RandomWidth(AUGMENTATION_FACTOR, seed=RANDOM_SEED),
    Rescaling(1/255.)
])
augmentaion_layer
def show_image_after_augmentation_layer(target_dir, class_names, augmentation_layer, scale= True):
    target_class = random.choice(class_names)
    target_dir = f"{target_dir}/{target_class}"
    random_image = random.choice(os.listdir(target_dir))
    random_image_path = target_dir + "/" + random_image
    print(random_image_path)
    img = mpimg.imread(random_image_path)
    plt.title(f"Original random image from class: {target_class}")
    plt.imshow(img);
    augmented_image = augmentation_layer(img, training=True)
    plt.figure()
    plt.title(f"augmented random image from class: {target_class}")
    if scale:
        plt.imshow(augmented_image / 255)
    else:
        plt.imshow(augmented_image)
show_image_after_augmentation_layer(target_dir=TRAIN_DIR, class_names=class_names, augmentation_layer=augmentaion_layer, scale=False)
base_model = tf.keras.applications.ResNet50V2(include_top=False)
base_model.trainable = False
input_layer = tf.keras.layers.Input(shape=IMAGE_SIZE + (3,), name="input_layer")
x = augmentaion_layer(input_layer)
x = base_model(x, training=False)
x = tf.keras.layers.GlobalAveragePooling2D(name="global_average_pooling2d")(x)
output_layer = Dense(len(class_names), activation=softmax, name="output_layer")(x)

model_1 = tf.keras.Model(input_layer, output_layer)
model_1.compile(
    loss=tf.keras.losses.CategoricalCrossentropy(),
    optimizer=tf.keras.optimizers.Adam(),
    metrics=["accuracy"]
)
model_checkpoint_path = "checkpoint/checkpoint.cpk"

checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(
    filepath=model_checkpoint_path,
    monitor="val_accuracy",
    save_best_only=True,
    save_weights_only=True,
    verbose=1
)
import datetime
def create_tensorboard_callback(dir_name, experiment_name):
    log_dir = dir_name + "/" + experiment_name + "/" + \
        datetime.datetime.now().strftime("%Y%m%d-%H%M%S")
    tensorboard_callback = tf.keras.callbacks.TensorBoard(
        log_dir=log_dir
    )
    print(f"Saving TensorBoard log files to: {log_dir}")
    return tensorboard_callback
    !mkdir -p history && touch history/history.csv
    model_1.summary()
history_1 = model_1.fit(
    train_data,
    epochs=EPOCHS,
    steps_per_epoch=len(train_data),
    validation_data=test_data,
    validation_steps=int(0.15 * len(test_data)),
    callbacks=[
        tf.keras.callbacks.CSVLogger("/kaggle/working/history/history.csv"),
        checkpoint_callback,
        create_tensorboard_callback(dir_name="tensorboard", experiment_name="wonders")
    ]
)
eval_1 = model_1.evaluate(test_data)
eval_1
model_1.save("wonders_model.h5")
def plot_loss_curves(history, metric="accuracy"):
    loss = history.history['loss']
    val_loss = history.history['val_loss']
    accuracy = history.history[metric]
    val_accuracy = history.history[f"val_{metric}"]
    epochs = range(len(history.history['loss']))
    plt.plot(epochs, loss, label='training_loss')
    plt.plot(epochs, val_loss, label='val_loss')
    plt.title('Loss')
    plt.xlabel('Epochs')
    plt.legend()
    plt.figure()
    plt.plot(epochs, accuracy, label='training_accuracy')
    plt.plot(epochs, val_accuracy, label='val_accuracy')
    plt.title('Accuracy')
    plt.xlabel('Epochs')
    plt.legend()
plot_loss_curves(history=history_1)
len(class_names), class_names
preds_probs = model_1.predict(test_data)
preds_probs
pred_classes = preds_probs.argmax(axis=1)
pred_classes[:10]
def get_predicted_labels_from_test_data(test_data):
    y_labels = []
    for images, labels in test_data.unbatch():
        y_labels.append(labels.numpy().argmax())
    return y_labels
y_labels = get_predicted_labels_from_test_data(test_data=test_data)
y_labels[:10]
from sklearn.metrics import accuracy_score
sklearn_accuracy = accuracy_score(y_true=y_labels,y_pred=pred_classes)
sklearn_accuracy
from sklearn.metrics import confusion_matrix
import itertools
import matplotlib
def make_confusion_matrix(y_true, y_pred, classes=None, figsize=(10, 10), text_size=15, norm=False, savefig=False):
    plt.rcParams.update({"font.size": text_size})
    cm = confusion_matrix(y_true, y_pred)
    cm_norm = cm.astype("float") / \
        cm.sum(axis=1)[:, np.newaxis]  # normalize it
    n_classes = cm.shape[0]  # find the number of classes we're dealing with
    fig, ax = plt.subplots(figsize=figsize)
    cax = ax.matshow(cm, cmap=plt.cm.Blues)
    fig.colorbar(cax)
    if classes:
        labels = classes
    else:
        labels = np.arange(cm.shape[0])
    ax.set(title="Confusion Matrix",
           xlabel="Predicted label",
           ylabel="True label",
           xticks=np.arange(n_classes),
           yticks=np.arange(n_classes),
           xticklabels=labels,
           yticklabels=labels)
    ax.xaxis.set_label_position("bottom")
    ax.xaxis.tick_bottom()
    threshold = (cm.max() + cm.min()) / 
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        if norm:
            plt.text(j, i, f"{cm[i, j]} ({cm_norm[i, j]*100:.1f}%)",
                     horizontalalignment="center",
                     color="white" if cm[i, j] > threshold else "black",
                     size=text_size)
        else:
            plt.text(j, i, f"{cm[i, j]}",
                     horizontalalignment="center",
                     color="white" if cm[i, j] > threshold else "black",
                     size=text_size)
    if savefig:
        fig.savefig("confusion_matrix.png")
make_confusion_matrix(y_true=y_labels,
                      y_pred=pred_classes,
                      classes=class_names,
                      figsize=(45, 45),
                      text_size=18)
from sklearn.metrics import classification_report
print(classification_report(y_true=y_labels,
                            y_pred=pred_classes))
from sklearn.metrics import classification_report
import pandas as pd
def get_f1_score_on_every_class_name(y_labels, y_true, class_names):
    classification_report_dict = classification_report(y_labels, y_true, output_dict=True)
    class_f1_scores = {}
    for k, v in classification_report_dict.items():
        if k == "accuracy": # stop once we get to accuracy key
            break
        else:
            class_f1_scores[class_names[int(k)]] = v["f1-score"]
    class_f1_scores
    f1_scores = pd.DataFrame({"class_names": list(class_f1_scores.keys()),
                            "f1-score": list(class_f1_scores.values())}).sort_values("f1-score", ascending=False)
    return f1_scores
f1_scores = get_f1_score_on_every_class_name(y_labels=y_labels, y_true=pred_classes, class_names=class_names)
f1_scores
import matplotlib.pyplot as plt
import pandas as pd
def plot_f1_scores_on_every_class_name(f1_scores, figsize = (10, 10)):
    fig, ax = plt.subplots(figsize=figsize)
    scores = ax.barh(range(len(f1_scores)), f1_scores["f1-score"].values)
    ax.bar_label(scores, label_type='center', c="white")
    ax.set_yticks(range(len(f1_scores)))
    ax.set_yticklabels(f1_scores["class_names"])
    ax.set_xlabel("F1-score")
    ax.set_title("F1-scores for 101 Different Food Classes")
    ax.invert_yaxis(); # reverse the order of our plot
plot_f1_scores_on_every_class_name(f1_scores=f1_scores, figsize=(15, 15))
def load_and_prep_image(filename, img_shape=224, scale=True):
    img = tf.io.read_file(filename)
    img = tf.image.decode_jpeg(img, channels=3)
    img = tf.image.resize(img, [img_shape, img_shape])
    if scale:
        return img/255.
    else:
        return img
import os
import random
def make_random_prediction(class_names, test_dir, qty: int = 3, figsize =(17, 10), fontsize: int = 12, image_shape=224):
    plt.figure(figsize=figsize)
    for i in range(qty):
        class_name = random.choice(class_names)
        filename = random.choice(os.listdir(test_dir + "/" + class_name))
        filepath = test_dir + "/" + class_name + "/" + filename
        print("filepath:", filepath)
        img = load_and_prep_image(filepath, scale=False, img_shape=image_shape)
        print("before:", img.shape)
        img_expanded = tf.expand_dims(img, axis=0)
        print("after: ", img_expanded.shape)
        pred_prob = model_1.predict(img_expanded) # get prediction probabilities array
        pred_class = class_names[pred_prob.argmax()] # get highest prediction probability index and match it class_names list
        plt.subplot(1, qty, i+1)
        plt.imshow(img/225.)
        if class_name == pred_class: # if predicted class matches truth class, make text green
            title_color = "g"
        else:
            title_color = "r"
        plt.title(f"actual: {class_name}, pred: {pred_class}, prob: {pred_prob.max():.2f}", c=title_color, fontdict= {'fontsize': fontsize})
        plt.axis(False);
make_random_prediction(class_names, test_dir=TEST_DIR, fontsize=10, qty=3, image_shape=400    
